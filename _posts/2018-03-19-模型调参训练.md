---
layout: post
title: 机器学习：模型调参训练
categories: 机器学习
comments: false
description: 
keywords: 训练
mathjax: true
---
### 有适用于模型调整的标准启发法吗？

这是一个常见的问题。简短的答案是，不同超参数的效果取决于数据。因此，不存在必须遵循的规则，您需要对自己的数据进行测试。即便如此，我们仍在下面列出了几条可为您提供指导的经验法则：

 * 训练误差应该稳步减小，刚开始是急剧减小，最终应随着训练收敛达到平稳状态。
 * 如果训练尚未收敛，尝试运行更长的时间。
 * 如果训练误差减小速度过慢，则提高学习速率也许有助于加快其减小速度。
   * 但有时如果学习速率过高，训练误差的减小速度反而会变慢。
 * 如果训练误差变化很大，尝试降低学习速率。
   * 较低的学习速率和较大的步数/较大的批量大小通常是不错的组合。
 * 批量大小过小也会导致不稳定情况。不妨先尝试 100 或 1000 等较大的值，然后逐渐减小值的大小，直到出现性能降低的情况。

重申一下，切勿严格遵循这些经验法则，因为效果取决于数据。请始终进行试验和验证。


#### 学习速率（步长）
每个回归问题都存在一个**金发姑娘**学习速率。“金发姑娘”值与**损失函数的平坦程度**相关。如果您知道损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-19-17-15-28.jpg)

