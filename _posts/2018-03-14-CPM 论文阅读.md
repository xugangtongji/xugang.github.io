---
layout: post
title: CPM论文阅读
categories: 肢体检测
comments: false
description: openpose的前身
keywords: openpose，肢体检测，CMU，CVPR
---
### convolutional pose machines, CVPR 2016
[主页](http://pearl.vasc.ri.cmu.edu/cpm/index.html)<br>
[Github](https://github.com/shihenw/convolutional-pose-machines-release)<br>
[论文](https://arxiv.org/abs/1602.00134)<br>
![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-14-15-14-21.jpg)

整个framework还是比较清晰的，也就是构建多个**FCN网络**来预测part/joint的heat maps，这多个FCN就构成了convolutional pose machines（CPM）。尽管CPM是一个**cascaded网络**，但是CPM是一个交互的sequence framework，即上一个FCN的上下文（contextual）会作为下一个FCN的输入,与残差有点相似了，因此可以解决**梯度弥散**的问题，也提高了CPM的**感受野**。
#### 本文的创新点： 
1.用各部位响应图来表达各部位之间的空间约束。响应图和特征图，一起作为下一级的输入。 
2.网络分为多个stage。各个阶段都有单独的Loss监督训练，避免过深网络难以优化的问题。 

#### 目标函数

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-14-22-45-14.jpg)

**怎么产生ground-truth heat maps?**
>生成的高斯函数模板，根据pose点图像坐标来建立响应图像。

#### 处理流程


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-14-20-29-34.jpg)

1. 第一阶段：从RGB图像直接预测每个部件的响应。即7层卷积，3层池化层，原始输入图片是368×368，经过3次池化得到46×46大小。有9个关节点，加上背景1，因此输出的响应图大小是46×46×10。<br>
2. 第二阶段：从RGB图像预测各部件响应，在卷积层中间部位多了一个Concat层，合并三个数据：原始图像卷积：RGB特征；阶段性的响应结果:空间特征 ；中心约束：真值的高斯响应图。  
3. 第三阶段：不再使用原始图像为输入，而是从第二阶段的中途取出一个**深度为X的特征图**作为输入。同样使用串联层综合三种因素：**纹理特征+空间特征+中心约束**。   

#### 训练
输出层的误差经过多层反向传播会大幅减小，即发生vanishing gradients现象。为解决此问题，本文在每个阶段的输出上都计算损失。这种方法称为intermediate supervision【中继监督】，可以保证底层参数正常更新。 

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-14-20-29-52.jpg)

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-14-20-34-28.jpg)  
<center>中继监督（黑色）和无中继监督（红色）</center>

#### 我的问题
1. 训练阶段每个stage进行中继学习，有相应的概率heatmap参与下一级的输入和当前stage的训练。那么，当测试的时候，这个真值heatmap是没有的。How? <br>
2. 随着stage的加深，相应的感受野变大，怎样实现的？感受野如何定义？<br>
3. 论文复现,训练 <br>