---
layout: page
title: 行为识别综述
categories: 项目
comments: false
description: 
keywords: 深度学习、行为识别
mathjax: true
---

视频理解行为存在的难点：
	1. 歧义性。例如，抽烟和喝水，接打电话，都有“举起手臂”的这么一个动作，对于单纯骨骼特征来说就很难区别的。
	2. 对于长视频检测来说，很难确定动作的起始和终止帧，目前有用扫描时间的窗口但大小很难确定，LSTM是输入整个序列后做出一个输出判断。

视频处理领域有4个基本流派：3D CNN、LSTM、optial flow、two stream。

经典方法IDT密集运动轨迹：
1.光流+轨迹 2013
缺点：特征维度高，速度慢，基本已经被学术界放弃了。
2.逐帧融合 2014 cvpr
把视频看出一系列的图像集合，每帧单独提取特征，再进行融合。
融合方法：
	- 逐帧； 
	- 后端融合lateFusion，高层卷积特征融合；
	- 输入端融合EarlyFusion，卷积11*11*3*10；
	- SlowFusion即3D卷积，

### 3D卷积



![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-10-09-15-28-34.jpg)

上面进行卷积操作的时间维度为3，在这个结构中，卷积层中每一个特征map都会与上一层中多个邻近的连续帧相连，网络提取了时间之间某种的相关性，因此捕捉运动信息。一个卷积map的同一位置的值是通过卷积上一层的三个连续的帧的同一个位置的局部感受野得到的。 
需要注意的是：3D卷积核只能从cube中提取一种类型的特征，因为在整个cube中卷积核的权值都是一样的，也就是共享权值，都是同一个卷积核（图中同一个颜色的连接线表示相同的权值）

**-1- 3D convolutional neural networks for human action recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2013, 35(1): 221-231.
-2- Learning Spatiotemporal Features with 3D Convolutional Networks.  2015-ICCV**

<https://pdfs.semanticscholar.org/52df/a20f6fdfcda8c11034e3d819f4bd47e6207d.pdf>

[http://vlg.cs.dartmouth.edu/c3d/c3d\_video.pdf](http://vlg.cs.dartmouth.edu/c3d/c3d_video.pdf)

C3D network的[项目主页和](http://vlg.cs.dartmouth.edu/c3d/)[github](https://github.com/facebook/C3D)

上面进行卷积操作的时间维度为3，在这个结构中，卷积层中每一个特征map都会与上一层中多个邻近的连续帧相连，网络提取了时间之间某种的相关性，因此捕捉运动信息。一个卷积map的同一位置的值是通过卷积上一层的三个连续的帧的同一个位置的局部感受野得到的。 

需要注意的是：3D卷积核只能从cube中提取一种类型的特征，因为在整个cube中卷积核的权值都是一样的，也就是共享权值，都是同一个卷积核（图中同一个颜色的连接线表示相同的权值）


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-10-09-15-33-05.jpg)


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-10-09-15-29-42.jpg)


 文中的3D CNN架构包含一个硬连线hardwired层、3个卷积层、2个下采样层和一个全连接层。每个3D卷积核卷积的立方体是连续7帧，每帧patch大小是60x40；

每帧提取五个通道的信息，分别是：灰度、x和y方向的梯度，x和y方向的光流。其中，前面三个都可以每帧都计算。然后水平和垂直方向的光流场需要两个连续帧才确定。所以是7x3 + (7-1)x2=33个特征maps。

除了3D卷积，加入额外的辅助高维特征：肢体骨骼+3D+光流

模型组合：投票制度；构造多个不同的3D CNN模型，因此它可以从输入捕捉潜在的互补信息，然后在预测阶段，每个模型都针对一个输入得到对应的输出，然后再组合这些输出得到最终的结果。

  该论文的贡献，其自组织为：

1）提出通过3D卷积操作核去提取视频数据的时间和空间特征。这些3D特征提取器在空间和时间维度上操作，因此可以捕捉视频流的运动信息。

2）基于3D卷积特征提取器构造了一个3D卷积神经网络。这个架构可以从连续视频帧中产生多通道的信息，然后在每一个通道都分离地进行卷积和下采样操作。最后将所有通道的信息组合起来得到最终的特征描述。

3）提出通过计算高层运动特征得到的辅助输出来增强模型。为了应对不同环境的使用，还综合多个不同的CNN架构去综合判断识别结果。



### 七牛云方案


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-09-01-00-23-44.jpg)



[Moments in Time挑战赛](https://mp.weixin.qq.com/s?__biz=MjM5NzAwNDI4Mg==&mid=2652194423&idx=1&sn=8d2ba45e5067703b5f7883aa7bbd8dca&chksm=bd0170e28a76f9f4ebb08e987c10dc0de72ed6c8333e0ce6c3248d95314dc426ab0bc174e6a0&scene=21#wechat_redirect)

今年 CVPR 2018 我们参加了 ActivityNet 竞赛。ImageNet 竞赛一个重要的维度升级版就是视频，之前视频数据只有几万、十几万量级，真正达到百万量级视频竞赛就是今年我们做的 Moments in time，这是第一个百万级的视频分类数据集，很特殊只有 3 秒，而且类别很抽象，里面有一个类别 open，你去开门、打开一个盒子、开柜子，只要 open 都放到一类里，很抽象，对人来说有很多经验很容易，但是对机器识别很难，解决这个事情要多个维度，要从 RGB 视觉维度做，光流维度做，目标检测维度抽特征，甚至还要做序列上的。我们决定参加这个的时候竞赛已经快结束，大概花一周时间做了七个模型，不同维度做七个模型。因为我们有一个 AVA 平台，可以分布式高效处理视频，可以分布式计算，所以七天完成这个任务，最后做到 63.7% 的准确率，拿到第三名。这展现了 AVA 平台的强大能力。

为了让更多的师生使用 AVA 深度学习平台，七牛云推出 CV 学术创新计划，免费向所有高校师生开放申请。计划包含免费的数据图床存储空间、计算机视觉主流公开数据集、自主标注的多领域数据，免费的数据集存储，以及整套的深度学习平台。为研究者提供数据标注、预处理、训练、在线上线 lab API 的完整能力。通过平台的开放，我们希望与更多伙伴进行合作，为计算机视觉创新而共同奋斗。

发送邮件至：atlab-review@qiniu.com
立刻申请七牛云 CV 学术创新计划




