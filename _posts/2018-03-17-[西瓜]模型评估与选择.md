---
layout: post
title: [西瓜]模型评估与选择
categories: 机器学习
comments: false
description: 
keywords: 机器学习，西瓜书
mathjax: true
---

#### 训练误差与泛化误差
当学习器把训练样本学得“太好”的时候（接近100%准确率），很大可能已经把训练样本的某些特征（绿色的都是植物）当作评判标准，这样就会导致泛化能力减弱，这种现象就是过拟合。欠拟合指的是对训练样本的一般性质尚未挑选总结出来。<br>
#### 评估方法
对一个数据集分割训练集和测试集：<br>
1. 留出法
2. 交叉验证
3. 留一法（只留一张测试，多次训练，适合小样本）
4. 自助法：随机自主采样，有0.368不被采样到。

#### 调参工程
对于原始数据集T，分割成测试和训练集，进行调参（步长调节），确实在当前参数下模型表现最好，然后固定参数在整个数据集上进行训练，最后交给用户。验证集和测试集的区别：测试集用来验证泛化能力，验证集用来模型选择和调参。

#### 查准率、查全率与F1


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-17-10-20-24.jpg)

**查准率 P（团队中人才占比）**： P=TP/TP诸葛亮+FP何珅   <br>
查全率 R（挑全人才的能力）：  R=TP/TP诸葛亮+FN韩非  <br>
查准率和查全率是一对矛盾的度量，两者是一个trade-off的关系。<br>
查准率关心的是”预测出正例的准确率”即提取出的例子，有多少是真正的正例。<br> 
查全率关心的是”预测出正例的覆盖性”即正例正值中，有多少被查出来。<br>
#### ROC和PR曲线

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-17-06-20-01.jpg)

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-17-10-19-22.jpg)

> True Class:真值；Hypothesized Class：预测值；F-measure：F1分数

先用分数（score），设置不同的阈值，得到一系列PR值序列，就画出了P-R曲线。对应曲线下的面积就是评价目标检测常用的AP定义。

F1是统计学中用来衡量二分类模型精确度的一种指标。它同时兼顾了分类模型的准确率和召回率。F1分数可以看作是模型准确率和召回率的一种加权平均，西瓜书还定义了$${F_\beta }$$,召回率的权重是准确率的beta倍。

F1认为PR一样重要定义：

$$ {F_1} = \frac{{2PR}}{{P + R}}$$


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-17-06-23-57.jpg)

ROC曲线指**受试者工作特征曲线** (receiver operating characteristic curve),是用构图法揭示敏感性和特异性的相互关系，先根据得分进行排序，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线，曲线下面积越大，诊断准确性越高。AUC的值就是ROC曲线下方围成区域的面积大小。和P-R曲线类似，ROC曲线用FPR作横轴，用TPR作纵轴，画曲线的过程类似挑选人才。<br>
**假正例率，何珅/何珅+强盗，滥用奸臣的能力**
$$
FPR=\frac{FP}{TN+FP}
$$

**真正例率，诸葛亮/诸葛亮+韩非，人才查全率，和Recall定义一样的**
$$
TPR=\frac{TP}{TP+FN}
$$


![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-17-10-56-07.jpg)

- PR曲线和ROC曲线的关系

PR曲线和ROC曲线都能评价分类器的性能。PR曲线的R值是等于ROC曲线中的TPR值；ROC曲线是单调的而PR曲线不是（根据它能更方便调参）；在正负样本分布得极不均匀(highly skewed datasets)的情况下（负样本数量更多），PRC比ROC能更有效地反应分类器的好坏。

![](http://p5iojc2zy.bkt.clouddn.com/_posts/_image/2018-03-17-11-26-10.jpg)



