---
title:  openpose library 肢体行为
layout: post
categories: 计算机视觉
comments: false
description: 
keywords: openpose
---



> openpose是CMU前沿计算中心开发的一个基于图像的人体姿态分析算法库，自2016年开源以来成为当前肢体关键点检测领域最为知名的算法。我的研究生毕业论文就引用了这个开源库，作为行为分析的特征提取方法。所以大家一起来瞻仰一下他们是怎么实现的，算法的优点和不足。以及我们可以用这个来做什么。

#### convolutional pose machines, CVPR 2016
首先来看一下，openpose出现之前深度学习是怎么计算肢体关键点的。其中OpenPose借鉴了很多CPM论文中的思想。



![](/images/blog/2018-03-14-15-14-21.jpg)

[主页](http://pearl.vasc.ri.cmu.edu/cpm/index.html)、[Github](https://github.com/shihenw/convolutional-pose-machines-release)、[论文](https://arxiv.org/abs/1602.00134)<br>

 整个framework还是比较清晰的，也就是构建多个**FCN网络**来预测part/joint的heat maps，这多个FCN就构成了convolutional pose machines（CPM）。尽管CPM是一个**cascaded网络**，但是CPM是一个交互的sequence framework，即上一个FCN的上下文（contextual）会作为下一个FCN的输入，与残差有点相似了，训练时采用中继训练，因此可以解决**梯度弥散**的问题，也提高了CPM的**感受野**。

本文的创新点： 
1.用各部位响应图来表达各部位之间的空间约束。响应图和特征图，一起作为下一级的输入。 
2.网络分为多个stage。各个阶段都有单独的Loss监督训练，避免过深网络难以优化的问题。 


目标函数

![](/images/blog/2018-03-14-22-45-14.jpg)

**怎么产生ground-truth heat maps?**
>生成的高斯函数模板，根据pose点图像坐标来建立响应图像。


**处理流程**


![](/images/blog/2018-03-14-20-29-34.jpg)

1. 第一阶段：从RGB图像直接预测每个部件的响应。即7层卷积，3层池化层，原始输入图片是368×368，经过3次池化得到46×46大小。有9个关节点，加上背景1，因此输出的响应图大小是46×46×10。<br>
2. 第二阶段：从RGB图像预测各部件响应，在卷积层中间部位多了一个Concat层，合并三个数据：原始图像卷积：RGB特征；阶段性的响应结果:空间特征 ；中心约束：真值的高斯响应图。  
3. 第三阶段：不再使用原始图像为输入，而是从第二阶段的中途取出一个**深度为X的特征图**作为输入。同样使用串联层综合三种因素：**纹理特征+空间特征+中心约束**。   

**训练**
输出层的误差经过多层反向传播会大幅减小，即发生vanishing gradients现象。为解决此问题，本文在每个阶段的输出上都计算损失。这种方法称为intermediate supervision【中继监督】，可以保证底层参数正常更新。 

![](/images/blog/2018-03-14-20-29-52.jpg)

![](/images/blog/2018-03-14-20-34-28.jpg)  
<center>中继监督（黑色）和无中继监督（红色）</center>

#### 我的问题
1. 训练阶段每个stage进行中继学习，有相应的概率heatmap参与下一级的输入和当前stage的训练。那么，当测试的时候，这个真值heatmap是没有的。How? <br>
2. 随着stage的加深，相应的感受野变大，怎样实现的？感受野如何定义？<br>
3. 论文复现,训练 <br>
4. 中继监督，目标函数是什么样子的？<br>

### openpose

OpenPose is a library（库） for real-time multi-person keypoint detection and multi-threading written in C++ using OpenCV and Caffe. (实时性，多线程，C++)，最早是基于[caffe\_rtpose](https://github.com/CMU-Perceptual-Computing-Lab/caffe_rtpose)（ZheC）框架开发的。

![](https://github.com/CMU-Perceptual-Computing-Lab/openpose/raw/master/doc/media/dance.gif)

Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields <br>

作者：Zhe Cao Tomas Simon Shih-En Wei Yaser Sheikh

摘要：我们提出了一种有效地检测图像中多个人的2D姿态的方法。 该方法使用非参数表示，我们将其称为**关节关联场（PAF）**，将身体骨骼与图像中的个体相关联。 该架构是基于**全局信息**的，实施的是一个贪心的自下而上的解析步骤，能够保持高精度和实时性，而不论图像中人的数量多少。 该架构旨在通过两个相同的预测分支，联合学习得到，**骨骼点位置及其关联场信息**。 我们的方法在COCO 2016关键点挑战赛中获得第一，并且在性能和效率方面都显着超过了MPII Multi-Person的当前最先进的方法。

![](/images/blog/2017-10-26-14-18-33.jpg)

#### face+hand+body
body：COCO数据集训练，18个bodykey；<br>
face：**没有相关论文** github issue#248：Face Keypoint Detector based on OpenCV face detecto. 单独使用是需要opencv的人脸检测器，使用body检测器就不用单独的人脸检测器，。作者透露是使用了传统的脸部标注数据和PanopticStudio的数据。<br>

hand：方法未知，训练数据是PanopticStudio+[论文](https://arxiv.org/pdf/1704.07809.pdf)<br>

代码中提到了hand/face heatmaps，有可能使用的是类似body检测的方法。<br>

![](https://github.com/CMU-Perceptual-Computing-Lab/openpose/raw/master/doc/media/pose_face_hands.gif)

### 简介：
openpose can detect human body, hand and facial keypoints (in total 130 keypoints) on single images.
openpose 可以同时检测面部+手+身体，总计130个关键点在一幅图像上。<br>
手部训练数据来源于[CMU Panoptic Dataset](http://domedb.perception.cs.cmu.edu/)(强大到不行的lab，480个相机，30个高清相机，和10深度相机，最后做成了这个身体，手部骨骼的数据库)
### Mutiview Bootstraping
利用多视角下的重投影来迭代训练，

![](http://p5iojc2zy.bkt.clouddn.com/2017-10-28-13-57-20.jpg)

![](http://p5iojc2zy.bkt.clouddn.com/2017-10-28-13-54-09.jpg)

### demo特性
- body的检测速度与人数多少没有关系
- 2x21-keypoint hand 检测，与检测人数成线性关系
- 70-keypoint face 检测，与检测人数成线性关系
- 可以配置多线程；数据 Image, video, webcam and IP camera reader；
- 所有的功能被打包成OpenPose Wrapper类
- face和hands检测也可以单独配置；

- - - - -
参考文献：
1.OpenPose Library 
[[github地址]](https://github.com/CMU-Perceptual-Computing-Lab/openpose)

2.Hand Keypoint Detection in Single Images using Multiview Bootstrapping ,*CPVR2017*
[[project page]](http://www.cs.cmu.edu/~tsimon/projects/mvbs.html)

3.The Panoptic Studio: A Massively Multiview System for Social Motion Capture (in ICCV 2015)
[[Panoptic Studio]](http://www.cs.cmu.edu/~hanbyulj/panoptic-studio/)

4.Convolutional Pose Machines
[[paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Wei_Convolutional_Pose_Machines_CVPR_2016_paper.pdf)

